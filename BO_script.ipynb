{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# This code was originally developed by Prof. Hiromasa Kaneko and the original version is found at https://github.com/hkaneko1985/python_doe_kspub\n",
    "# Modified by Masanori Kodera \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, RBF, ConstantKernel, Matern, DotProduct\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "number_of_selecting_samples = 10\n",
    "regression_method = 'gpr_one_kernel'\n",
    "acquisition_function = 'EI'\n",
    "fold_number = 10 \n",
    "relaxation = 0.01\n",
    "\n",
    "dataset = pd.read_csv('selected_samples.csv', index_col=0, header=0) #input file\n",
    "remaining_samples = pd.read_csv('remaining_samples.csv', index_col=0, header=0) # remaining samples's list\n",
    "\n",
    "y = dataset.iloc[:, 5]\n",
    "x = dataset.iloc[:, 1:4]\n",
    "\n",
    "deleting_variables = x.columns[x.std() == 0]\n",
    "x = x.drop(deleting_variables, axis=1)\n",
    "x_prediction = remaining_samples.iloc[:, 1:4].drop(deleting_variables, axis=1)\n",
    "cumulative_variance = np.zeros(x_prediction.shape[0]) \n",
    "\n",
    "kernels = ConstantKernel() * RBF() + WhiteKernel() + DotProduct()\n",
    "\n",
    "# Bayesian optimization\n",
    "next_samples = pd.DataFrame([], columns=x_prediction.columns)  \n",
    "for sample_number in range(number_of_selecting_samples):\n",
    "    autoscaled_y = (y - y.mean()) / y.std()\n",
    "    autoscaled_x = (x - x.mean()) / x.std()\n",
    "    autoscaled_x_prediction = (x_prediction - x.mean()) / x.std()\n",
    "    model = GaussianProcessRegressor(alpha=0, kernel=kernels) \n",
    "    model.fit(autoscaled_x, autoscaled_y)  \n",
    "    \n",
    "    if sample_number == 0:\n",
    "\n",
    "        autoscaled_estimated_y, autoscaled_estimated_y_std = model.predict(autoscaled_x, return_std=True)\n",
    "        estimated_y = autoscaled_estimated_y * y.std() + y.mean() \n",
    "        estimated_y_std = autoscaled_estimated_y_std * y.std()  \n",
    "        estimated_y = pd.DataFrame(estimated_y, index=x.index, columns=['estimated_y'])\n",
    "        estimated_y_std = pd.DataFrame(estimated_y_std, index=x.index, columns=['std_of_estimated_y'])\n",
    "        \n",
    "        y_for_save = pd.DataFrame(y)\n",
    "        y_for_save.columns = ['actual_y']\n",
    "        y_error_train = y_for_save.iloc[:, 0] - estimated_y.iloc[:, 0]\n",
    "        y_error_train = pd.DataFrame(y_error_train)\n",
    "        y_error_train.columns = ['error_of_y(actual_y-estimated_y)']\n",
    "        results_train = pd.concat([y_for_save, estimated_y, y_error_train, estimated_y_std], axis=1) \n",
    "        results_train.to_csv('estimated_y_in_detail_{0}.csv'.format(regression_method))  \n",
    "        \n",
    "        cross_validation = KFold(n_splits=fold_number, random_state=9, shuffle=True) \n",
    "        autoscaled_estimated_y_in_cv = cross_val_predict(model, autoscaled_x, autoscaled_y)  \n",
    "        estimated_y_in_cv = autoscaled_estimated_y_in_cv * y.std() + y.mean()  \n",
    "        estimated_y_in_cv = pd.DataFrame(estimated_y_in_cv, index=x.index, columns=['estimated_y'])\n",
    "\n",
    "        y_error_in_cv = y_for_save.iloc[:, 0] - estimated_y_in_cv.iloc[:, 0]\n",
    "        y_error_in_cv = pd.DataFrame(y_error_in_cv)\n",
    "        y_error_in_cv.columns = ['error_of_y(actual_y-estimated_y)']\n",
    "        results_in_cv = pd.concat([y_for_save, estimated_y_in_cv, y_error_in_cv], axis=1) \n",
    "        results_in_cv.to_csv('estimated_y_in_cv_in_detail_{0}.csv'.format(regression_method))  \n",
    "        \n",
    "    estimated_y_prediction, estimated_y_prediction_std = model.predict(autoscaled_x_prediction, return_std=True)\n",
    "    estimated_y_prediction = estimated_y_prediction * y.std() + y.mean()\n",
    "    estimated_y_prediction_std = estimated_y_prediction_std * y.std()\n",
    "\n",
    "    acquisition_function_prediction = (estimated_y_prediction - max(y) - relaxation * y.std()) * \\\n",
    "                                           norm.cdf((estimated_y_prediction - max(y) - relaxation * y.std()) /\n",
    "                                                     estimated_y_prediction_std) + \\\n",
    "                                           estimated_y_prediction_std * \\\n",
    "                                           norm.pdf((estimated_y_prediction - max(y) - relaxation * y.std()) /\n",
    "                                                     estimated_y_prediction_std)\n",
    "\n",
    "    acquisition_function_prediction[estimated_y_prediction_std <= 0] = 0\n",
    "\n",
    "    estimated_y_prediction = pd.DataFrame(estimated_y_prediction, x_prediction.index, columns=['estimated_y'])\n",
    "    estimated_y_prediction_std = pd.DataFrame(estimated_y_prediction_std, x_prediction.index, columns=['std_of_estimated_y'])\n",
    "    acquisition_function_prediction = pd.DataFrame(acquisition_function_prediction, index=x_prediction.index, columns=['acquisition_function'])\n",
    "\n",
    "    if sample_number == 0:\n",
    "        estimated_y_prediction.to_csv('estimated_y_prediction_{0}.csv'.format(regression_method)) \n",
    "        estimated_y_prediction_std.to_csv('estimated_y_prediction_{0}_std.csv'.format(regression_method)) \n",
    "        acquisition_function_prediction.to_csv('acquisition_function_prediction_{0}_{1}.csv'.format(regression_method, acquisition_function))  \n",
    "\n",
    "    next_samples = pd.concat([next_samples, x_prediction.loc[acquisition_function_prediction.idxmax()]], axis=0)\n",
    "    \n",
    "    x = pd.concat([x, x_prediction.loc[acquisition_function_prediction.idxmax()]], axis=0)\n",
    "    y = pd.concat([y, estimated_y_prediction.loc[acquisition_function_prediction.idxmax()].iloc[0]], axis=0)\n",
    "    x_prediction = x_prediction.drop(acquisition_function_prediction.idxmax(), axis=0)\n",
    "    dataset= pd.concat([dataset, remaining_samples.loc[acquisition_function_prediction.idxmax()]], axis=0)\n",
    "    remaining_samples = remaining_samples.drop(acquisition_function_prediction.idxmax(), axis=0)\n",
    "    cumulative_variance = np.delete(cumulative_variance, np.where(acquisition_function_prediction.index == acquisition_function_prediction.iloc[:, 0].idxmax())[0][0])\n",
    "\n",
    "    next_samples.to_csv('next_samples_bo_{0}_{1}.csv'.format(regression_method, acquisition_function)) \n",
    "    remaining_samples.to_csv('new_remaining_samples.csv')\n",
    "    dataset.to_csv('new_selected_samples.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
